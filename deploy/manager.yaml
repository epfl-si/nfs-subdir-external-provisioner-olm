# Namespace and deployment for the OLM controller manager.
#
# Simply put, this runs your “operator's operator” pod, if you
# consider OLM as being an “operator's operator's operator“.
#
# This file can (almost) be used stand-alone (if you uncomment and
# edit the `image:` field; or alternatively, if you let the `sed`
# business in `make deploy` take care of that for you). This file is
# also fed into the bundling pipeline, so that the Deployment object
# below becomes part of the operator manifests as described in
# https://olm.operatorframework.io/docs/tasks/creating-operator-manifests/
# (On the other hand, the Namespace is eliminated at `operator-sdk
# generate bundle` time, because OLM prefers to manage the namespace
# as it pleases.)

apiVersion: v1
kind: Namespace
metadata:
  labels:
    control-plane: controller-manager
    app.kubernetes.io/name: namespace
    app.kubernetes.io/instance: system
    app.kubernetes.io/component: manager
    app.kubernetes.io/created-by: nfs-subdir-ext-provisioner-olm
    app.kubernetes.io/part-of: nfs-subdir-ext-provisioner-olm
    app.kubernetes.io/managed-by: kustomize
  name: nfs-ext-olm-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  # The name and namespace must match the ones that `operator-sdk
  # generate bundle` expects, lest it ignore the Deployment entirely.
  name: nfs-ext-olm-controller-manager
  namespace: nfs-ext-olm-system
  labels:
    control-plane: controller-manager
    app.kubernetes.io/name: deployment
    app.kubernetes.io/instance: controller-manager
    app.kubernetes.io/component: manager
    app.kubernetes.io/created-by: nfs-subdir-ext-provisioner-olm
    app.kubernetes.io/part-of: nfs-subdir-ext-provisioner-olm
spec:
  selector:
    matchLabels:
      control-plane: controller-manager
  replicas: 1
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: manager
      labels:
        control-plane: controller-manager
    spec:
      # TODO(user): Uncomment the following code to configure the nodeAffinity expression
      # according to the platforms which are supported by your solution.
      # It is considered best practice to support multiple architectures. You can
      # build your manager image using the makefile target docker-buildx.
      # affinity:
      #   nodeAffinity:
      #     requiredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #         - matchExpressions:
      #           - key: kubernetes.io/arch
      #             operator: In
      #             values:
      #               - amd64
      #               - arm64
      #               - ppc64le
      #               - s390x
      #           - key: kubernetes.io/os
      #             operator: In
      #             values:
      #               - linux
      securityContext:
        runAsNonRoot: true
      # As the bundled ClusterServiceVersion contains a “preview” of
      # the controller's RBAC (under `spec.install.spec.permissions`
      # and `spec.install.spec.clusterPermissions`), the
      # serviceAccountName below must match the one referenced by the
      # RBAC objects living under ../config/rbac/
      serviceAccountName: nfs-ext-olm-controller-manager
        # TODO(user): For common cases that do not require escalating privileges
        # it is recommended to ensure that all your Pods/Containers are restrictive.
        # More info: https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted
        # Please uncomment the following code if your project does NOT have to work on old Kubernetes
        # versions < 1.19 or on vendors versions which do NOT support this field by default (i.e. Openshift < 4.11 ).
        # seccompProfile:
        #   type: RuntimeDefault
      containers:
      - args:
        - --leader-elect
        - --leader-election-id=nfs-subdir-ext-provisioner-olm
#        image: controller:latest
        name: manager
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - "ALL"
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 15
          periodSeconds: 20
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8081
          initialDelaySeconds: 5
          periodSeconds: 10
        # TODO(user): Configure the resources accordingly based on the project requirements.
        # More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
        resources:
          limits:
            cpu: 500m
            memory: 128Mi
          requests:
            cpu: 10m
            memory: 64Mi
      terminationGracePeriodSeconds: 10
